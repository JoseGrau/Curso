# -*- coding: utf-8 -*-
"""utils.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EBHcJ37RnwCEvUPUfeH-hY011XRpSh9O
"""

import numpy as np
import pandas as pd

"""En este código guardamos varias funciones útiles para el curso que serán llamadas para hacer diferentes ejercicios de machine learning.

Empezamos con una función para inicializar los pesos. Devolvemos el tipo float32 para evitar posibles problemas con Theano y Tensorflow.
"""

def init_weigth_and_bias(M1, M2):
  W = np.random.randn(M1, M2)/np.sqrt(M1+M2)
  b = np.zeros(M2)
  return W.astype(np.float32), b.astype(np.float32)

"""El filtro se utiliza para las redes neuronales convolucionales."""

def init_filter(shape, poolsz):
  w = np.random.randn(*shape) / np.sqrt(np.prod(shape[1:]) + shape[0] * np.prod(shape[2:] / np.prod(poolsz)))
  return w.astype(np.float32)

"""Ahora definimos varias funciones de activación."""

def relu(x):
  return x * (x>0)

def sigmoid(A):
  return 1 / (1 + np.exp(-A))

def softmax(A):
  expA = np.exp(A)
  return expA / expA.sum(axis = 1, keepdims = True)

"""La función de coste para clasificación binaria usando la función sigmoide como activación."""

def sigmoid_cost(T, Y):
  return -(T*np.log(Y) + (1-T) * np.log(1-Y)).sum()

"""Función de coste para softmax (Softmax cross-entropy function)."""

def cost(T, Y):
  return -(T * np.log(Y)).sum()

"""Misma función que cost, pero optimizada, ya que solo realiza operaciones sobre valores no nulos de la matriz T."""

def cost2(T, Y):
  N = len(T)
  return -np.log(Y[np.arange(N), T]).sum()

"""Una función para ver el error"""

def err_rate(targets, predictions):
  return np.mean(targets != predictions)

"""Función indicadora para la matriz Y."""

def y2indicator(y):
  N = len(y)
  K = len(set(y))
  ind = np.zeros(N, K)
  for i in range(N):
    ind[i, y[i]] = 1
  return ind

"""Recordamos que para este ejercicio usamos los datos del reto "Facial Expression Recognition" de Kaggle:

https://www.kaggle.com/ashishpatel26/facial-expression-recognitionferchallenge?

A continuación, definimos una función para preprocesar estos datos, donde añadimos una condición para completar los datos del estado 1, repitiéndolos, ya que hay sustancialmente menos ejemplos de este tipo. También hay que tener en cuenta que la primera línea del CSV es un índice, por lo que usamos la condición first para saltarla.
"""

def getData(balance_ones = True):
  Y = []
  X = []
  first = True 

  for line in open(fer2013.csv):
    if first:
      first = False
    else:
      row = line.split(",")
      Y.append(int(row[0]))
      X.append([int(p) for p in row[1].split()])
  
    X, Y = np.array(X) / 255.0, np.array(Y)
  
  if balance_ones:
    X0, Y0 = X[Y!=1, :], Y[Y!=1, :]
    X1 = X[Y==1, :]
    X1 = np.repeat(X1, 9, axis=0)
    X = np.vstack([X0,X1])
    Y = np.concatenate((Y0, [1]*len(X1)))

  return X, Y

"""La siguiente función se usa en redes neuronales convucionales. Mantiene la estructura de los datos (imágenes)."""

def getImageData():
  X, Y = getData()
  N, D = X.shape
  d = int(np.sqrt(D))
  X = X.reshape(N, 1, d, d)
  return X, Y

"""Por último, esta función se limita a obtener los datos con etiquetas 0 o 1 con el fin de realizar clasificación binaria. Notar que no se compensa la falta de datos etiquetados con 1."""

def getBinaryData():
  Y = []
  X = []
  first = True 

  for line in open(fer2013.csv):
    if first:
      first = False
    else:
      row = line.split(",")
      y = (int(row[0]))
      if y == 0 or y == 1:
        Y.append(y)
        X.append([int(p) for p in row[1].split()])
  
  return np.array(X) / 255.0, np.array(Y)